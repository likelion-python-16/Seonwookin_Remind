1. “데이터 큐레이션”
   (어떤방법으로 분석해서 데이터를 정제하는지? 핵심적인 기술, 아이디어 부재, 정제된 깨끗한 데이터를 만들어주는 기술이 핵심역량)

● 의미
	•	**“큐레이션(Curation)”**이란
→ 무작위로 흩어진 데이터를 모으고,
→ 쓸모있게 정리·선별하고,
→ 필요한 기준대로 분류/가공해서
→ 사용자가 바로 쓸 수 있게 제공하는 일입니다.

● 실제 예시
	•	논문 데이터를 분야별/키워드별/연도별로 정렬
	•	생명과학 실험 데이터를 결측값, 오류값 제거해서
통계적으로 신뢰성 있게 정제
	•	여러 기관의 데이터를 한 곳에서, 한글/영어 등으로 통일해서 보여주기
	•	중복 데이터, 오타, 부정확한 정보 자동/수동으로 검증

● 실무 중요성
	•	AI/자동분석보다 “좋은 데이터/믿을만한 데이터”가 훨씬 더 중요
	•	실제 연구·기업 현장에서는
정제된 데이터를 모아주는 서비스에 “돈을 지불”함

● Django, 파이썬으로 할 수 있는 예시
	•	각종 데이터 파일(csv, excel, API)을 읽어서
결측/이상값/중복 자동 검출
	•	필요한 항목만 골라서 필터링, 정렬
	•	웹에서 다운로드/검색/시각화 제공
	•	데이터 업로드/검증/정제 자동화 서비스 제공

⸻

2. “데이터-논문 연결” 서비스
   (공공데이터 만으로는 불가능 하겠지만.. 여기서 파생하면 좋을듯)

● 의미
	•	데이터를 논문, 저자, 주제, 기관 등과
자동으로 연결해서
“이 데이터가 어디 논문에서 쓰였는지”,
“이 논문이 어떤 데이터를 사용했는지”
빠르게 찾고 확인할 수 있게 해주는 서비스

● 실제 예시
	•	논문 검색할 때, “사용된 데이터셋”을 바로 보여줌
	•	데이터셋을 보면, “참조 논문 리스트”, “관련 연구” 자동 표시
	•	논문 메타데이터(제목, 저자, 키워드)와
데이터베이스의 “데이터 정보”를 연결해 보여줌

● 실무 중요성
	•	연구자는 빠른 정보 확인/신뢰성 검증/재현 연구에 필요
	•	특허, 사업화, 규제 대응 등에도 “출처 정보” 중요

● Django, 파이썬으로 할 수 있는 예시
	•	논문 메타데이터와 데이터셋 정보를 자동 매칭하는 API
	•	논문/데이터 통합 검색, 시각화, 다운로드 서비스
	•	키워드/분야별 “논문-데이터 네트워크” 그래프 표시
	•	자동 인용, 자동 연결 기능 (AI/딥러닝 활용 가능)


 @ 정제된 깨끗한 데이터를 만들어주는 기술이 핵심역량
